{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "ML_Lab_Assignment-2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmH-m4azoQhv"
      },
      "source": [
        "### Name: Sayantan Banerjee\n",
        "### Roll No: 2018IMT-093\n",
        "### Course: Machine Learning Lab\n",
        "### Course Code: ITIT - 4107\n",
        "### Deadline : 25 September 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E9Wvq9PoH8F"
      },
      "source": [
        "# With Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKtMd91YoH8N",
        "outputId": "00b0524c-9350-484c-d959-be5dfe9a1790"
      },
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "def normalize(probs):\n",
        "    sum_probs = sum(probs)\n",
        "    if sum_probs == 0:          # smoothing is done here, if sum_of_probs = 0, means that one or more conditional probabilities are 0 \n",
        "        return normalize([1 for each in probs])\n",
        "    return [each/sum_probs for each in probs]\n",
        "\n",
        "def normalize_dict(d):\n",
        "    total = sum(d.values())\n",
        "    for each in d:\n",
        "        d[each] /= total\n",
        "    return d\n",
        "\n",
        "def train(train_data):\n",
        "    # returns a belief\n",
        "    prior = defaultdict(int)\n",
        "    counter = {i: {x: [0, 0] for x in range(10)} for i in range(784)}\n",
        "    for data in train_data:\n",
        "        data = convert_data(data)\n",
        "        label = data[0]\n",
        "        pixels = data[1:]\n",
        "        prior[label] += 1\n",
        "        for i in range(len(pixels)):\n",
        "            counter[i][label][pixels[i]] += 1\n",
        "    prior = normalize_dict(prior)\n",
        "    for i in range(784):\n",
        "        for x in range(10):\n",
        "            counter[i][x] = normalize(counter[i][x])\n",
        "    return prior, counter\n",
        "\n",
        "def argmax(l):\n",
        "    maximum = 0\n",
        "    result = None\n",
        "    for i in range(len(l)):\n",
        "        if l[i] > maximum:\n",
        "            maximum = l[i]\n",
        "            result = i\n",
        "    return result\n",
        "\n",
        "# returns int\n",
        "def predict(data):\n",
        "    global belief, prior\n",
        "    probs = [prior[x] for x in range(10)]\n",
        "    data = convert_data(data)\n",
        "    for i in range(len(data)):\n",
        "        for x in range(10):\n",
        "            probs[x] *= belief[i][x][data[i]]\n",
        "        probs = normalize(probs)\n",
        "    return argmax(probs)\n",
        "\n",
        "def convert_data(data):\n",
        "    return [data[0]] + [1 if each > 0 else 0 for each in data[1:]]\n",
        "\n",
        "\n",
        "def run_test(data):\n",
        "    no_of_rights,no_of_wrongs = 0,0\n",
        "    metrics = {i:[no_of_rights,no_of_wrongs] for i in range(10)}\n",
        "    right_output = 0\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        row = data[i]\n",
        "        label = row[0]\n",
        "        pixels = row[1:]\n",
        "        prediction = predict(pixels)\n",
        "\n",
        "        if label==prediction:\n",
        "            metrics[label][0] += 1\n",
        "            right_output+=1\n",
        "        else:\n",
        "            metrics[label][1] += 1\n",
        "    acc = right_output/10000\n",
        "    return acc, metrics\n",
        "\n",
        "    \n",
        "    \n",
        "        \n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    train_data = [list(map(int, line.strip().split(\",\"))) for line in open(\"mnist_train.csv\").read().strip().split(\"\\n\")]\n",
        "    prior, belief = train(train_data)\n",
        "    \n",
        "    test_data = [list(map(int, line.strip().split(\",\"))) for line in open(\"mnist_test.csv\").read().strip().split(\"\\n\")]\n",
        "    accuracy,metrics = run_test(test_data)\n",
        "    print(\"Accuracy: {}\".format(accuracy))\n",
        "    for i in metrics:\n",
        "        print('For {} error % = : {}'.format(i, 100*(metrics[i][1]/sum(metrics[i]))))\n",
        "    print(\"Total Error: {}\".format(100*(1-accuracy)))\n",
        "    #print(metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8412\n",
            "For 0 error % = : 9.591836734693878\n",
            "For 1 error % = : 4.405286343612335\n",
            "For 2 error % = : 17.151162790697676\n",
            "For 3 error % = : 16.33663366336634\n",
            "For 4 error % = : 19.45010183299389\n",
            "For 5 error % = : 29.7085201793722\n",
            "For 6 error % = : 11.273486430062631\n",
            "For 7 error % = : 15.369649805447471\n",
            "For 8 error % = : 22.279260780287473\n",
            "For 9 error % = : 16.15460852329039\n",
            "Total Error: 15.880000000000006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-ndHXvMoH8T"
      },
      "source": [
        "# Without Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH4mZeDRoH8V",
        "outputId": "c02a4656-71fd-4e21-838d-53fd4de8be72"
      },
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "def normalize(probs):\n",
        "    sum_probs = sum(probs)\n",
        "    #if sum_probs == 0:          # smoothing is done here, if sum_of_probs = 0, means that one or more conditional probabilities are 0 \n",
        "        #return normalize([1 for each in probs])\n",
        "    return [each/sum_probs for each in probs]\n",
        "\n",
        "def normalize_dict(d):\n",
        "    total = sum(d.values())\n",
        "    for each in d:\n",
        "        d[each] /= total\n",
        "    return d\n",
        "\n",
        "def train(train_data):\n",
        "    # returns a belief\n",
        "    prior = defaultdict(int)\n",
        "    counter = {i: {x: [0, 0] for x in range(10)} for i in range(784)}\n",
        "    for data in train_data:\n",
        "        data = convert_data(data)\n",
        "        label = data[0]\n",
        "        pixels = data[1:]\n",
        "        prior[label] += 1\n",
        "        for i in range(len(pixels)):\n",
        "            counter[i][label][pixels[i]] += 1\n",
        "    prior = normalize_dict(prior)\n",
        "    #for i in range(784):\n",
        "        #for x in range(10):\n",
        "            #counter[i][x] = normalize(counter[i][x])\n",
        "    return prior, counter\n",
        "\n",
        "def argmax(l):\n",
        "    maximum = 0\n",
        "    result = None\n",
        "    for i in range(len(l)):\n",
        "        if l[i] > maximum:\n",
        "            maximum = l[i]\n",
        "            result = i\n",
        "    return result\n",
        "\n",
        "# returns int\n",
        "def predict(data):\n",
        "    global belief, prior\n",
        "    probs = [prior[x] for x in range(10)]\n",
        "    data = convert_data(data)\n",
        "    for i in range(len(data)):\n",
        "        for x in range(10):\n",
        "            probs[x] *= belief[i][x][data[i]]\n",
        "        #probs = normalize(probs)\n",
        "    return argmax(probs)\n",
        "\n",
        "def convert_data(data):\n",
        "    return [data[0]] + [1 if each > 0 else 0 for each in data[1:]]\n",
        "\n",
        "\n",
        "def run_test(data):\n",
        "    no_of_rights,no_of_wrongs = 0,0\n",
        "    metrics = {i:[no_of_rights,no_of_wrongs] for i in range(10)}\n",
        "    right_output = 0\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        row = data[i]\n",
        "        label = row[0]\n",
        "        pixels = row[1:]\n",
        "        prediction = predict(pixels)\n",
        "\n",
        "        if label==prediction:\n",
        "            metrics[label][0] += 1\n",
        "            right_output+=1\n",
        "        else:\n",
        "            metrics[label][1] += 1\n",
        "    acc = right_output/10000\n",
        "    return acc, metrics\n",
        "\n",
        "    \n",
        "    \n",
        "        \n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    train_data = [list(map(int, line.strip().split(\",\"))) for line in open(\"mnist_train.csv\").read().strip().split(\"\\n\")]\n",
        "    prior, belief = train(train_data)\n",
        "    \n",
        "    test_data = [list(map(int, line.strip().split(\",\"))) for line in open(\"mnist_test.csv\").read().strip().split(\"\\n\")]\n",
        "    accuracy,metrics = run_test(test_data)\n",
        "    print(\"Accuracy: {}\".format(accuracy))\n",
        "    for i in metrics:\n",
        "        print('For {} error % = : {}'.format(i, 100*metrics[i][1]/sum(metrics[i])))\n",
        "    #print(metrics)\n",
        "    print(\"Total Error: {}\".format((1-accuracy)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.1092\n",
            "For 0 error % = : 0.20408163265306123\n",
            "For 1 error % = : 99.8237885462555\n",
            "For 2 error % = : 97.96511627906976\n",
            "For 3 error % = : 99.20792079207921\n",
            "For 4 error % = : 99.59266802443992\n",
            "For 5 error % = : 99.55156950672645\n",
            "For 6 error % = : 99.68684759916492\n",
            "For 7 error % = : 93.09338521400778\n",
            "For 8 error % = : 100.0\n",
            "For 9 error % = : 99.90089197224975\n",
            "Total Error: 89.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cEVwUhMoH8Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}